Code for my Poker Database project. 

The basic idea behind the project was to be able to enter and store hands of poker being played into a database to then be queried later based on a wide range of search criteria (strength of hand, number of players, size of the pot, winner of the hand, etc). I felt the abliity to quickly and efficiently review past hands played by you or others would be a good way to learn from previous mistakes and improve play going forward. I also included a few other calculations of pre-flop and post-flop win percentages if you wanted to examine some hands in a vacuum.

In general the project flows as such: 
The Card class is a basic class that encodes the functionality of a single playing card in poker. It has a basic comparison overloaded operator as well as an equivalence operator and has two fields for the suit and value of the card being played.

The Deck class is another basic class which behaves as a deck of cards in poker. Throughout the project a hand is stored as a vector of ints and it is the Deck class's responsibility to correlate each of the integers with a specific card. It does this by keeping a size 52 vector of cards as its main field with each integer being an index into that vector to retrieve the card.

The Hand class was the next thing developed and it does a lot of the heavy lifting in terms of actually playing out a hand of poker. It's main method is the resolve_hand method which takes in a vector of integers and returns the strength score associated with those cards by getting the best five and determinining what strength hand they represent. The higher the strength score the better. It also has several auxillary methods that start with gen. These methods are meant to generate the data that was either stored in the database for use down the line in calculations are as data for the Python machine learning models used to analyze pre-flop and post-flop strength.
The main method of deriving solid data about the win percentage of a hand was monte carlo simulation to derive the average win rate of a hand over a large number of iterations. The Hand class is the class responsible for a large number of these simulations to get reliable data.

The Game class was the next developed and it is responsible for most of the logic related to the betting and game flow of poker. It handles storing card values, bet amounts, player names, stack amounts, pot sizes, and more in order to fully encapsulate the full flow of a hand to be stored in the datbase.

The Replay class is the class responsible for actually recreating the hand for someone to examine after the fact. It recieves the information from the database and uses it to allow the user to step through the hand again while also including interesting statistics to give more context for the hand and decisions made by the POV player (the only player for which we know their cards from the beginning). These stats are calculated in the game class for queried from the database and include pot odds each time the POV player must call, pre-flop odds, as well as flop, river, and turn odds and the current strength of the hand.

Lastly the Query class is the class that does most of the interfacing with the database. For this project I used sqlite which supports a serverless database for simplicity. Nevertheless, the Query class takes in the search criteria and forms a custom SQL query to scan the database for hands that match said critera. It then creates the replay objects from the database information and allows them to replay the hand for the user.


As an accessory to this I also went in with custom data constructed from the hand class into CSV files and used the Python pandas, numpy, and scikit learn packages in order to do some data analytics and visualization as well construct models to evaluate the strength of hands post flop. I was able to use a combination of polynomial regression and a random forest regressor to calculate the strength of a hand post flop with 98.3% accuracy. The fields used to calculate this value include a custom metric I designed called expected value (EV) which looks at all the possible continuations and maps out the relative win percentage of each one and finds the mean value. Running that data with polynomial regression gave an accurate model to predict the win percentage with the expected value which was then used in the random forest regressor to get the final value.
